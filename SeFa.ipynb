{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJDJLE3v0HNr"
   },
   "source": [
    "# Fetch Codebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "JqiWKjpFa0ov"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/zami/projects/Factorized_CryoEM_wgan/sefa-cryowgan'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title\n",
    "import os\n",
    "#os.chdir('/content')\n",
    "#CODE_DIR = 'sefa'\n",
    "#!git clone https://github.com/genforce/sefa.git $CODE_DIR\n",
    "#os.chdir(f'./{CODE_DIR}')\n",
    "os.chdir(\"./sefa-cryowgan\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SessionState.py',\n",
       " 'LICENSE',\n",
       " 'README.md',\n",
       " 'interface.py',\n",
       " 'sefa.py',\n",
       " 'latent_codes',\n",
       " '__pycache__',\n",
       " '.ipynb_checkpoints',\n",
       " 'models',\n",
       " 'checkpoints',\n",
       " 'utils.py']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQ_IXBZr8YcJ"
   },
   "source": [
    "# Define Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['cryoEM_wgan', 'pggan_celebahq1024', 'pggan_bedroom256', 'pggan_livingroom256', 'pggan_diningroom256', 'pggan_kitchen256', 'pggan_church256', 'pggan_tower256', 'pggan_bridge256', 'pggan_restaurant256', 'pggan_classroom256', 'pggan_conferenceroom256', 'pggan_person256', 'pggan_cat256', 'pggan_dog256', 'pggan_bird256', 'pggan_horse256', 'pggan_sheep256', 'pggan_cow256', 'pggan_car256', 'pggan_bicycle256', 'pggan_motorbike256', 'pggan_bus256', 'pggan_train256', 'pggan_boat256', 'pggan_airplane256', 'pggan_bottle256', 'pggan_chair256', 'pggan_pottedplant256', 'pggan_tvmonitor256', 'pggan_diningtable256', 'pggan_sofa256', 'stylegan_ffhq1024', 'stylegan_celebahq1024', 'stylegan_bedroom256', 'stylegan_cat256', 'stylegan_car512', 'stylegan_celeba_partial256', 'stylegan_ffhq256', 'stylegan_ffhq512', 'stylegan_livingroom256', 'stylegan_diningroom256', 'stylegan_kitchen256', 'stylegan_apartment256', 'stylegan_church256', 'stylegan_tower256', 'stylegan_bridge256', 'stylegan_restaurant256', 'stylegan_classroom256', 'stylegan_conferenceroom256', 'stylegan_animeface512', 'stylegan_animeportrait512', 'stylegan_artface512', 'stylegan2_ffhq1024', 'stylegan2_church256', 'stylegan2_cat256', 'stylegan2_horse256', 'stylegan2_car512'])\n"
     ]
    }
   ],
   "source": [
    "from models import MODEL_ZOO\n",
    "print(MODEL_ZOO.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "id": "ijKTlG5GeTd3"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "import os.path\n",
    "import io\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "import cv2\n",
    "import PIL.Image\n",
    "\n",
    "import torch\n",
    "\n",
    "from models import parse_gan_type\n",
    "from utils import to_tensor\n",
    "from utils import postprocess\n",
    "from utils import load_generator\n",
    "from utils import factorize_weight\n",
    "\n",
    "\n",
    "def sample(generator, gan_type, num=1, seed=11):\n",
    "    \"\"\"Samples latent codes.\"\"\"\n",
    "    #torch.manual_seed(seed)                                                                    TURNED OFF SEEDING!!!!\n",
    "    #codes = torch.randn(num, generator.z_space_dim).cuda()     CHANGED FOR OUR GAN\n",
    "    codes = torch.randn((num, 100, 1, 1)).cuda()\n",
    "    codes = pixel_norm_layer(generator.net[0](codes))\n",
    "    '''\n",
    "    if gan_type == 'pggan':\n",
    "        codes = generator.layer0.pixel_norm(codes)\n",
    "    elif gan_type == 'stylegan':\n",
    "        codes = generator.mapping(codes)['w']\n",
    "        codes = generator.truncation(codes, trunc_psi=0.7, trunc_layers=8)\n",
    "    elif gan_type == 'stylegan2':\n",
    "        codes = generator.mapping(codes)['w']\n",
    "        codes = generator.truncation(codes, trunc_psi=0.5, trunc_layers=18)\n",
    "    '''\n",
    "    codes = codes.detach().cpu().numpy()\n",
    "    return codes\n",
    "\n",
    "def pixel_norm_layer(x):\n",
    "    \"\"\"Implements pixel-wise feature vector normalization layer.\"\"\"\n",
    "    norm = torch.sqrt(torch.mean(x ** 2, dim=1, keepdim=True) + 1e-8)\n",
    "    return x / norm\n",
    "\n",
    "\n",
    "def synthesize(generator, gan_type, codes):\n",
    "    \"\"\"Synthesizes images with the give codes.\"\"\"\n",
    "    '''\n",
    "  if gan_type == 'pggan':\n",
    "    images = generator(to_tensor(codes))['image']\n",
    "  elif gan_type == 'cryowgan':   #################################FOR US!!\n",
    "     return generator(to_tensor(codes))\n",
    "  elif gan_type in ['stylegan', 'stylegan2']:\n",
    "    images = generator.synthesis(to_tensor(codes))['image']\n",
    "      '''\n",
    "    #images = generator(to_tensor(codes)) ##########\n",
    "    images = generator(to_tensor(codes), synthesize=False)\n",
    "    images = postprocess(images)\n",
    "    return images\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def imshow(images, col, viz_size=128):\n",
    "    \"\"\"Shows images in one figure.\"\"\"\n",
    "    num, height, width, channels = images.shape\n",
    "    assert num % col == 0\n",
    "    row = num // col\n",
    "\n",
    "    # Create an empty array to hold the fused image\n",
    "    # Initialize the fused_image with 3 channels (for RGB)\n",
    "    fused_image = np.zeros((viz_size * row, viz_size * col, 3), dtype=np.uint8)\n",
    "\n",
    "    for idx, image in enumerate(images):\n",
    "        i, j = divmod(idx, col)\n",
    "        y = i * viz_size\n",
    "        x = j * viz_size\n",
    "        \n",
    "        # Resize image if it's not the desired size\n",
    "        if height != viz_size or width != viz_size:\n",
    "            image = cv2.resize(image, (viz_size, viz_size))\n",
    "        \n",
    "        # Handle grayscale images by converting them to 3 channels\n",
    "        if channels == 1:\n",
    "            image = np.repeat(image, 3, axis=-1)  # Repeat the grayscale image across 3 channels\n",
    "        \n",
    "        # Place the image into the correct position in the fused image\n",
    "        fused_image[y:y + viz_size, x:x + viz_size] = image\n",
    "\n",
    "    # Convert to uint8 if not already in that format\n",
    "    fused_image = np.asarray(fused_image, dtype=np.uint8)\n",
    "\n",
    "    # Directly display the image in the notebook\n",
    "    pil_image = Image.fromarray(fused_image)\n",
    "    pil_image.show()\n",
    "\n",
    "    return pil_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7gkmrVW8eR1"
   },
   "source": [
    "# Select a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "NoWI4fPQ6Gnf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building generator for model `cryoEM_wgan` ...\n",
      "Finish building generator.\n",
      "Loading checkpoint from `../sefa-cryowgan/checkpoints/run26_10k_checkpoint_netG.tar` ...\n",
      "Finish loading checkpoint.\n"
     ]
    }
   ],
   "source": [
    "#@title { display-mode: \"form\", run: \"auto\" }\n",
    "model_name = \"cryoEM_wgan\" #@param ['stylegan_animeface512', 'stylegan_car512', 'stylegan_cat256', 'pggan_celebahq1024', 'stylegan_bedroom256']\n",
    "\n",
    "generator = load_generator(model_name, '../sefa-cryowgan/checkpoints/run26_10k_checkpoint_netG.tar')\n",
    "gan_type = parse_gan_type(generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDStH1O5t1KC"
   },
   "source": [
    "# Sample Latent Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "qlRGKZbJt9hA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 100, 1, 1)\n",
      "(12, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "#@title { display-mode: \"form\", run: \"auto\" }\n",
    "\n",
    "num_samples = 12 #@param {type:\"slider\", min:1, max:8, step:1}\n",
    "noise_seed = 0 #@param {type:\"slider\", min:0, max:1000, step:1}\n",
    "\n",
    "codes = torch.randn((num_samples,100,1,1)).detach().numpy()\n",
    "print(codes.shape)\n",
    "\n",
    "images2 = synthesize(generator, gan_type, codes)#codes) #torch.randn((num_samples, 100, 1, 1)).cuda()\n",
    "print(images2.shape)\n",
    "#imshow(images2, col=num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=384x512 at 0x7F19F97C7700>\n"
     ]
    }
   ],
   "source": [
    "print(imshow(images2, col=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MmRPN3xz8jCH"
   },
   "source": [
    "# Factorize & Edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ccONBF60mVir",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=384x512 at 0x7F199C54BF70>\n"
     ]
    }
   ],
   "source": [
    "#@title { display-mode: \"form\", run: \"auto\" }\n",
    "\n",
    "layer_idx = \"0\" #@param ['all', '0-1', '2-5', '6-13']\n",
    "semantic_1 = -1 #@param {type:\"slider\", min:-3.0, max:3.0, step:0.1}\n",
    "semantic_2 = 0 #@param {type:\"slider\", min:-3.0, max:3.0, step:0.1}\n",
    "semantic_3 = 0 #@param {type:\"slider\", min:-3.0, max:3.0, step:0.1}\n",
    "semantic_4 = 0 #@param {type:\"slider\", min:-3.0, max:3.0, step:0.1}\n",
    "semantic_5 = 0 #@param {type:\"slider\", min:-3.0, max:3.0, step:0.1}\n",
    "\n",
    "# Fast implementation to factorize the weight by SeFa.\n",
    "layers, boundaries, _ = factorize_weight(generator, layer_idx)\n",
    "\n",
    "new_codes = codes.copy()\n",
    "for sem_idx in range(5):\n",
    "  boundary = boundaries[sem_idx:sem_idx + 1]\n",
    "  step = eval(f'semantic_{sem_idx + 1}')\n",
    "  if gan_type == 'cryowgan':\n",
    "    new_codes += (boundary.reshape(1, 100, 1, 1) * step)  #CHANGED TO INCLUDE CRYOWGAN\n",
    "    \n",
    "  elif gan_type =='pggan':            \n",
    "    new_codes += boundary * step\n",
    "    \n",
    "  elif gan_type in ['stylegan', 'stylegan2']:\n",
    "    new_codes[:, layers, :] += boundary * step\n",
    "new_images = synthesize(generator, gan_type, new_codes)\n",
    "print(imshow(new_images, col=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7faa6a1841304b539cf5862db76ea130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Layer Index:', index=1, options=('all', '0-1', '2-5', '6-13'), val…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.update_visual(layer_idx, semantic_1, semantic_2, semantic_3, semantic_4, semantic_5)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Define your layer and semantic controls as interactive widgets\n",
    "layer_idx = widgets.Dropdown(\n",
    "    options=['all', '0-1', '2-5', '6-13'],\n",
    "    value='0-1',\n",
    "    description='Layer Index:',\n",
    ")\n",
    "\n",
    "semantic_1 = widgets.FloatSlider(\n",
    "    value=0,\n",
    "    min=-3.0,\n",
    "    max=3.0,\n",
    "    step=0.1,\n",
    "    description='Semantic 1:',\n",
    "    continuous_update=True,\n",
    ")\n",
    "\n",
    "semantic_2 = widgets.FloatSlider(\n",
    "    value=0,\n",
    "    min=-3.0,\n",
    "    max=3.0,\n",
    "    step=0.1,\n",
    "    description='Semantic 2:',\n",
    "    continuous_update=True,\n",
    ")\n",
    "\n",
    "semantic_3 = widgets.FloatSlider(\n",
    "    value=0,\n",
    "    min=-3.0,\n",
    "    max=3.0,\n",
    "    step=0.1,\n",
    "    description='Semantic 3:',\n",
    "    continuous_update=True,\n",
    ")\n",
    "\n",
    "semantic_4 = widgets.FloatSlider(\n",
    "    value=0,\n",
    "    min=-3.0,\n",
    "    max=3.0,\n",
    "    step=0.1,\n",
    "    description='Semantic 4:',\n",
    "    continuous_update=True,\n",
    ")\n",
    "\n",
    "semantic_5 = widgets.FloatSlider(\n",
    "    value=0,\n",
    "    min=-3.0,\n",
    "    max=3.0,\n",
    "    step=0.1,\n",
    "    description='Semantic 5:',\n",
    "    continuous_update=True,\n",
    ")\n",
    "\n",
    "# Define a function that will update the visuals in real-time\n",
    "def update_visual(layer_idx, semantic_1, semantic_2, semantic_3, semantic_4, semantic_5):\n",
    "    clear_output(wait=True)  # Clear previous output to update in real time\n",
    "\n",
    "    '''\n",
    "    # Display the selected values\n",
    "    print(f'Layer Index: {layer_idx}')\n",
    "    print(f'Semantic 1: {semantic_1}')\n",
    "    print(f'Semantic 2: {semantic_2}')\n",
    "    print(f'Semantic 3: {semantic_3}')\n",
    "    print(f'Semantic 4: {semantic_4}')\n",
    "    print(f'Semantic 5: {semantic_5}')\n",
    "    '''\n",
    "    # Fast implementation to factorize the weight by SeFa.\n",
    "    layers, boundaries, _ = factorize_weight(generator, layer_idx)\n",
    "\n",
    "    new_codes = codes.copy()\n",
    "    for sem_idx, step in enumerate([semantic_1, semantic_2, semantic_3, semantic_4, semantic_5]):\n",
    "        boundary = boundaries[sem_idx:sem_idx + 1]\n",
    "        if gan_type == 'pggan':\n",
    "            new_codes += boundary * step\n",
    "        elif gan_type == 'cryowgan':\n",
    "            new_codes += (boundary.reshape(1, 100, 1, 1) * step)  #CHANGED TO INCLUDE CRYOWGAN\n",
    "        elif gan_type in ['stylegan', 'stylegan2']:\n",
    "            new_codes[:, layers, :] += boundary * step\n",
    "    new_images = synthesize(generator, gan_type, new_codes)\n",
    "    imshow(new_images, col=3)\n",
    "\n",
    "# Use `interact` to create the interactive UI and trigger `update_visual`\n",
    "interact(update_visual, \n",
    "         layer_idx=layer_idx, \n",
    "         semantic_1=semantic_1, \n",
    "         semantic_2=semantic_2, \n",
    "         semantic_3=semantic_3, \n",
    "         semantic_4=semantic_4, \n",
    "         semantic_5=semantic_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SeFa",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
